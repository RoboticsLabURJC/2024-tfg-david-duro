---
title: Finished Q-Learning 1D
date: 2025-01-20 9:00:00 +0100
tags: [phase 3]
author: david
img_path: /assets/img/
toc: true
comments: true
---

## Index

- [Decreased speed discretisation](#decreased-speed-discretisation)
- [Fixed RLidar](#fixed-rlidar)
- [Example and data analysis](#example-and-data-analysis)


## Decreased speed discretisation

The agent accelerates by increasing its speed by `0.1`. This implies that if we discretise too sharply the agent may not notice subtle changes in velocity, so the best value for discretisation is `0.1`.

## Fixed RLidar

In order to use lidar, the agent must be moving, as long as it is static, the rays detect the origin as an obstacle. To solve this problem, noise has been added to the way the origin of the rays is calculated.

```python
def add_origin_perturbation(origin, magnitude=0.001):
    """Add noise to origin"""
    perturbation = np.random.uniform(-magnitude, magnitude, size=2)
    return origin + np.array([perturbation[0], perturbation[1], 0]) 
```

## Example and data analysis

This graph shows how the agent converges to a solution after a number of steps, even from different positions.
![](final_1d/dist_diffs.png)


Epsilon evolution.
![](final_1d/epsilon.png)

Rewards and steps per episode.
![](final_1d/eps_steps.png)

In the video, two phases can be distinguished, the first in which the agent is positioned in a random place and the second in which he lines up between the two cars.
[example video](https://drive.google.com/file/d/1UJGxviEJHpsycFnmCeQeAKRZs01Jk2MR/view?usp=sharing)